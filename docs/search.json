[
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Introduction about Remote-sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 The introduction of remote sensing\nRemote sensing collects remotely sensed images by special cameras, which help researchers “sense” things about the earth. And it is that the process of detecting and monitoring the physical characteristics of an area by measuring reflected and emitted radiation from a certain distance.For example, forest fires can be mapped from space, seeing a much larger area than from the ground.\n\n\n1.1.2 Sensor\n\n1.1.2.1 Type\n\n\n\n\n\n\n\nActive sensor\nPassive sensor\n\n\n\n\nUsing light sources from its own\nUsing light sources from the sun\n\n\ncannot penetrate dense cloud cover\npenetrate the atmosphere\n\n\n\n\n\n\n\n\nIn addition, they can also be divided into imaging and non-imaging methods according to the recording method.\nImaging mode sensors represent the intensity of the received electromagnetic wave energy in the form of images, such as aerial cameras, scanners, imaging spectrometers.\nNon-imaging mode sensorsway to detect the intensity of the electromagnetic wave energy of the ground in the form of digital, curved graphical representation, such as radiometer, infrared radiation thermometer.\n\n\n1.1.2.2 Component\n1.Collector: collects the electromagnetic energy from the ground. For example, lenses for aerial cameras, reflectors for scanners, etc.\n2.Detector: converts the collected radiant energy into chemical or electrical energy.\n3.Processors: Process the detected signals, such as chemical or electrical energy. For example, film development and fixing, amplification of electrical signals, filtering, modulation, conversion, etc.\n4.Output: Outputs the images and data obtained. For example, photographic film, magnetic tape recorders, etc.\n\n\n\n\n\nProcessing. Source: From Yujin Pan\n\n\n\n\n\n\n\n1.1.3 Electromagnetic Spectrum\nElectromagnetic energy travels in waves and spans a broad spectrum from very long radio waves to very short gamma rays. The human eye can only detect only a small portion of this spectrum called visible light.\nProtective Atmosphere\nThe atmosphere protects us from a range of high-energy waves that are harmful to life. It likewise absorbs electromagnetic radiation. Among these are mainly water vapour, carbon dioxide and ozone.These regions of the spectrum with wavelengths that can pass through the atmosphere are referred to as “atmospheric windows.” Some microwaves can even pass through clouds, which make them the best wavelength for transmitting satellite communication signals. Because most electromagnetic radiation from space is unable to reach the surface of the Earth, for long-term observations, it is best to have your detector on an orbiting satellite.\n\n\n\n\n\nElectromagnetic Spectrum. Source:(https://science.nasa.gov/ems/01_intro)\n\n\n\n\n\n\n1.1.4 Remotely sensed data\n\nFormat\n\nThe remotely sensed data is raster,mostly GeoTIFF. But LiDAR is the point data.\n\nResolution\n\nResolution has a important role in how data from a sensor can be used. there are four types of resolution to consider for any dataset-radiometric, spatial, spectral, and temporal.\n\n\n\n\n\n\n\n\nResolution Types\nDescription\nExample\n\n\n\n\nspatial\nthe size of the raster grid per pixel\n20cm or 30m\n\n\nspectral\nthe number of bands\nBand 2 - blue (0.45-0.51 wavelength)\n\n\ntemporal\nthe time it revisits\ndaily or every 7 days\n\n\nRadiometric\nthe number of bits representing the energy recorded\n2 bit, 4 bit, or 8 bit"
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Introduction about Remote-sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nRemote sensing has a wide range of applications in many fields. For example, Remote sensing is widely used in agriculture.Traditionally, satellite imagery has been used for crop condition assessment and type mapping of crops, but due to the limited resolution of the sensors, satellites have been used over large areas. With technological advances, finer subscale green can enable remote sensing applications in the field for disaster assessments such as droughts and floods(Wójtowicz M,2016).Through the application of remote sensing, producers and governments can prevent natural disasters in advance and minimise economic losses.Remote sensing also plays an important role in crop yield forecasting. In the Southern Alberta of Canada, for example, remote sensing is used to assess the extent to which the area is vulnerable to drought conditions and to make yield forecasts. This can provide some support for local agricultural planning and reduce economic risk(Xu W,2011)."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Introduction about Remote-sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n1Remote sensing technology has been widely used in many fields, such as environmental protection, geological exploration, weather forecasting, agricultural production and urban planning. It provides us with a wealth of information about the Earth and gives us a better understanding of its changes and evolution.\n2.It can be used to produce a variety of maps and spatial information products such as digital elevation models, vegetation index maps, land use/cover maps, etc. These products can provide accurate descriptions and analyses of the Earth’s surface features.\n3.The rapid development of remote sensing technology has resulted in much lower data acquisition costs and more efficient data processing and analysis. This has allowed an increasing number of institutions and individuals to use remote sensing technology for research and applications.\n4.The applications of remote sensing data in many areas are yet to be further developed, for example, in the field of urban planning and environmental protection, remote sensing data can help us to better assess and predict the impact of urban development and environmental change, and improve the sustainability of cities and the environment.\nThrough this week’s study, I have gained an initial understanding of remote sensing, which I have not studied before. It is useful for me.I have learnt about the types of remote sensors, the format of remote sensing data and the resolution this week. However, my extra-curricular study of remote sensing is far from adequate. I have only studied the application areas of remote sensing in detail from agriculture this week, but I have not studied marine exploration and emergency disaster relief in depth."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Welcome to my learning-diary on remote-sensing."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Introduce about Synthetic Aperture Radar (SAR)",
    "section": "",
    "text": "This is my presentation. Please visit link: https://ucfnyp0.github.io/week2_xaringan/week2.html."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Remote sensing data",
    "section": "3.1 summary",
    "text": "3.1 summary\n\n3.1.1 sensor scanner\nHow to acquire multispectral image data\n\npush broom\n\nCollection method: The detector is perpendicular to the direction of flight of the spacecraft and acquires one image at a time\nData collection: Measure all pixels in a row of images at the same time\nExample:Spot and Orbview\n\n\n\n\n\npush broom. Source:(https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/16262/Push-Broom-and-Whisk-Broom-Sensors)\n\n\n\n\n\nWhisk broom\n\nCollection method: The detector collects the field of view scanned by the detector as the direction of the rotating mirror changes\nData collection: Acquisition of images in a wide range of narrow spectral bands from the visible to mid-infrared spectrum\nExample:Landsat\n\n\n\n\n\nWhisk broom. Source:(https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/16262/Push-Broom-and-Whisk-Broom-Sensors)\n\n\n\n\n\nCompare\n\nA push broom scanner receives a stronger signal than a whisk broom scanner, because it looks at each pixel area for longer.\n\n\n3.1.2 Connection\n\n3.1.2.1 geometric connection\nwhy we need to doing the geometric connection?\n\nView angle (off-nadir)\nNadir means directly down\nTopography (e.g. hills not flat ground)\nWind (if from a plane)\nRotation of the earth (from satellite)\n\nhow we do the geometric connection?\n\nIdentify the GPS\ncompute the geometric transformation coefficients and optain the geographic coordinates\nresample to populate new output grid\n\nRMSE\nThe model with the lowest RMSE will fit best—-always set the value is RMSE\n\nIn order to reduce the PMSE, we need to re-sample the final raster.\nResample methods\n\nNearest Neighbor\nLinear\nCubic\nCubic spline\n\n\n\n\n\n\nre-sample. Source:(https://andrewmaclachlan.github.io/CASA0023-lecture-3/?panelset3=dn2&panelset4=ratio2&panelset5=pca2#23)\n\n\n\n\n\n\n3.1.2.2 Atmospheric correction\nwhy we do the atmospheric connection?\n\nAtmospheric scattering\nTopographic attenuation\n\nAnd in biophysical parameters, we need to do the atmosphere connection. for example, temperature, lead area index, NDVI\nAtmospheric correction types\n\nRelative\n\nNormalize intensities of different bands within a single image and normalize intensities of bands from many dates to one date\n\nAbsolute\n\nuse the atmospheric radiative transfer models to change digital brightness values into scaled reflectance and then compare these scaled surface reflectance values across the planet.\ndata requirements–an atmopsheric model, local atmopsheric visibility, Image altitude\n\n\n3.1.2.3 Orthorectification correction\n\nwhen use the orthorectification correction?\n\nRaw satellite imagery contain distortions, which are induced by sensor orientation, topographical variation and the curvature of the earth.\n\naccurate elevation models are key.\n\nFeature distortion on raw imagery is heavily impacted by terrain variation. An accurate elevation model is required to calculate the effect of terrain variation on the image pixels.\n\n\n3.1.2.4 Radiometric Calibration\nRadiometric calibration is a crucial part of processing multispectral imagery, it enables the conversion of raw digital numbers (from the raw imagery), to sensor reflectance or irradiance, and then to surface reflectance values. Using a radiometric workflow enables the collection of repeatable reflectance data over different flights, dates, and weather conditions.\nWithout radiometric calibration, you may see the following effects:\n\nUnderexposed images, especially surrounding bright objects on the landscape\nIrregular coloration\nIndex values, such as NDVI, that appear to change dramatically and unexpectedly + near roads or buildings\nExtreme banding or patchiness in the mosaic"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Remote sensing data",
    "section": "3.2 Application",
    "text": "3.2 Application\nFrom some reading learning, it is important to apply the atmospheric correction to the remote sensing of coastal waters. The atmospheric correction process is applied to remove the effects of the atmosphere that contribute to the signal measured by a satellite sensor. The objective of this process is the discrimination, from top-of-atmosphere radiance, of the signal emerging from the sea carrying information on the materials suspended and dissolved in seawater. The atmospheric correction of coastal data is challenged by the presence of continental aerosols, bottom reflectance, and adjacency of land.\n\nWhat’s more, about the geometric connection,this paper shows the geometric correction process done in the Coimbatore imagery to improve the quality and it shows the process of distortion removed .Finally they get the georectified image using ERDAS(Baboo and Devi, 2011). 增添东西"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Remote sensing data",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nIn this week’s study, I learnt about remote scanners and calibration, among other things. Before using remote sensing data, we have to carry out data pre-processing, such as atmospheric correction, to eliminate the influence of atmospheric medium on the brightness value of remote sensing images, so that the remote sensing images reflect the real surface reflectance of the features, which can provide the basic data for the subsequent extraction and application of remote sensing information. What’s more, geometric correction of remote sensing is a fundamental step in remote sensing image processing and an important link in the application of remote sensing technology. Through geometric correction, accurate correspondence can be established between remote sensing images in terms of spatial position and actual ground position, providing basic data for remote sensing information extraction and application."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "::: {#refs} ::: {#refs Baboo, Dr.S.S., Devi, M.R., 2011. Geometric Correction in Recent High Resolution Satellite Imagery: A Case Study in Coimbatore, Tamil Nadu. IJCA 14, 32–37. https://doi.org/10.5120/1808-2324}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary for CASA0023",
    "section": "",
    "text": "Preface\nWelcome to my learning diary for CASA0023!\nMy name is . I graduated from in China with a Bachelor’s degree in Urban and Rural Planning.My research interests are mainly in the areas of spatial accessibility and urban public facilities optimisation, and I hope that my postgraduate studies will enable me to understand and learn more about the rich and advanced technologies that guide my studies and work on urban planning.\nThanks to Andy for guiding me and the course!"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\nstudy city:New York\n\nstudy policy: OneNYC 2050\n\nstudy topic: urban heated island\n\n\n\n\n\n\nOneNYC2050. Source: OneNYC 2050\n\n\n\n\n\n4.1.1 Background of Policy\nClimate change is a growing crisis for cities. High temperatures, on the other hand, are one of the most important aspects of the climate crisis, which has become the number one cause of death due to weather conditions in the United States. By the 2050s, the average temperature in New York City is expected to rise by 5.7 degrees Fahrenheit, and up to 1,500 people will die each summer from the heat.\n\n\n4.1.2 Specific Policy\nglobal policy : The Paris Agreement\nThe global response to the threat of climate change should be strengthened by achieving carbon neutrality and aggressive reductions in greenhouse gas emissions as soon as possible.\nMetropolitan policy: OneNYC 2050: VOLUME 7 OF 9- A LIVABLE CLIMATE\n\nCreating a liveable climate, responding positively to the Paris Agreement, taking action on climate change, especially for the most vulnerable communities, and upholding climate justice\nCommit to a just transition to carbon neutrality, climate resilience and a clean economy to improve environmental quality for all and redressing injustices\nInvest in infrastructure that mitigates climate risks, such as vegetation planting Forge partnerships on climate solutions across communities, sectors and regions to share the benefits\n\n增加其他国家对于热岛效应问题的方法 ppt中的"
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nIn this part, i will concern about how to use the EO data to resolve the urban heated island. In the following, there are one case and one reading to explain.\n\n4.2.1 Major Summer Heat Spots using Landsat-8 Thermal Satellite data\n\nData Collection\n\nEarth observation data- the Landsat8 data in summer\nOpen street map- the great London\n\nData Analysis\n\nTo generate a dataset that presents the LST spatial distribution and the corresponding hotspots for GLA, a five-year (2016-2020) time series of satellite-derived 100 m daytime LST images (in °C) is employed. The utilized data correspond only to summer months (i.e. June, July and August) so as to capture the hotspots with the most important impact on thermal discomfort, human health and energy demand.\nIn addition to the average LST (avgLST), the avgLST standard deviation, minimum and maximum for each city block are also estimated.\nFinally, the former statistics are stored as new attributes in the Urban Atlas polygons and the updated vectors are then exported as a new shapefile.\n\nOutput\n\n\n\n\n\n\nGeopackage. Source: Methodology and Deliverables Report_LONDON_ARTi\n\n\n\n\n\n\n\n\n\nGeopackage. Source: Methodology and Deliverables Report_LONDON_ARTi\n\n\n\n\n\n\n4.2.2 Social Inequities in Urban Heat and Greenspace: Analyzing Climate Justice in Delhi,India\nThis study quantifies exposure through the Urban Heat Risk Index (UHRI) and proximity to green spaces through the Normalised Difference Vegetation Index (NDVI) at ward level in Delhi to consider the urban social The distribution of inequalities in terms of burdens and benefits.\n\nthe dependent variable\n\nHeat exposure was estimated using the urban heat risk index (UHRI), a composite index of biophysical factors related to urban heat.And the equation is UHRI = [LST (z score) + NDBI (z score)] − NDVI (z score).\n\nLST is the land surface temperature, which is calculated from the Landsat data. NDBI was assessed by calculating the NDVI (normalized difference vegetation index). The UHRI thus takes all three into account as an indication of the spatial extent and intensity of the urban heat island.\n\n\n\n\n\nUHRI & NDVI. Source: Social Inequities in Urban Heat and Greenspace: Analyzing Climate Justice in Delhi,India\n\n\n\n\n\nthe independent variable\nsocio-demographic vulnerability, denoted by children, caste, and family size\nhousing-related vulnerability, denoted by household access to assets, electricity,and home ownership\nemployment-related vulnerability, denoted by literacy and involvement in agriculture\nthe output\n\n\n\n\n\n\nGeneralized estimating equation for predicting May UHRI using ward level socio-demographic variables. Source: Social Inequities in Urban Heat and Greenspace: Analyzing Climate Justice in Delhi,India\n\n\n\n\nThe UHRI is significantly positively associated with the proportion of children, SC, agricultural workers, households with assets and households with electricity (p < 0.01), but negatively associated (p < 0.005) with the proportion of educated residents, households that own a home and larger households.\n\nThrough correlation analysis and spatial visualisation of areas with high heat exposure indices, government funding for social vulnerability related factors such as households with severe poverty and electricity, schools, in addition to focusing not only on the heat island environment in the central city, it was shown through the strong correlation between agricultural labour and NDVI that the government should also focus on the population in the urban periphery. The correlation study aims to make a valuable contribution to the integration of climate justice considerations into climate change planning in Delhi by demonstrating which vulnerable groups should be prioritised in the policy if the urban heated island."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThrough the focus on high temperatures in the New York City 2050 plan, I have focused my attention on urban heat island issues, hoping to disentangle and propose specific strategies for 2050 planning goals through remote sensing data analysis, rather than macro planning. An example is the delivery of the UK Hotspot Toolkit. Through the collection of EO data, SUHI data is obtained and spatially visualised to give the government and citizens a clear picture of the hotspots that need to be focused on, providing specific geographical information on the location of the next solutions to the urban heat island problem. The Indian literature, on the other hand, provides possible correlates for addressing climate equity and can assist the government in providing direction for addressing equity issues. However, I believe that the current work is still far from adequate and that workflows need to be proposed for New York to mitigate the urban heat island problem and achieve climate equity, such as how to green the infrastructure and how to conduct urban temperature implementation monitoring."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Introduction to the Google Earth Engine\nGoogle Earth Engine combines data from hundreds of satellites and Earth observation datasets with powerful cloud computing to display high-resolution, timely and accurate remote sensing information, providing a platform for remote sensing data analysis.\nStrength: It permits geospatial analysis at scale + massive datasets + planetary scale analysis + quickly (within seconds)\n\n\n5.1.2 How to use the GEE\n\nuse the javascript code\nvar to define the variable\nee to acquire the EO data\nsome items\nGeometry : point/line/polygon with no attributes\nFeature : geometry with attributes\nFeature collection : several features with attributes, and it can be used for the storage, querying, analysis and visualisation of geographical information.\nImageCollection : A collection of multiple satellite images (Images). These images can be from different times, sensors, resolutions etc. They can be used to study different surface features such as vegetation cover, land use, climate change,eg:ee.ImageCollection(‘LANDSAT/LC08/C02/T1_L2’)\n\n\n\n\n\n\n\nCommon Earth Engine object classes. Source: GEE\n\n\n\n\n\n5.1.2.1 Set the Geometry\n//select the point\nvar point = ee.Geometry.Point([108.95000, 34.26667])\nMap.centerObject(Xian, 10)\n\n\n5.1.2.2 Load and filter the EO data\nvar oneimage_study_area_cloud = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n.filterDate('2019-01-01', '2022-12-10')\n.filterBounds(xian)  // Intersecting ROI\n.filter(ee.Filter.lt(\"CLOUD_COVER\", 0.1));\n\n\n\n\n\nXian. Source: Code by Yujin Pan\n\n\n\n\nIt shows the band information of landsat8 in the “Inspector”\n\n\n\n\n\nBand Information. Source: Code by Yujin Pan\n\n\n\n\nLoad the single image\n“127036” represents the longitude and latitude, and “20220517” represents the date I want to acquire.\nvar image = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_127036_20220517')\nvar rgbvis = {\n  bands: ['SR_B4','SR_B3','SR_B2'],\n  min: 5000,\n  max: 15000};\nMap.addLayer(image,rgbvis,\"landsat8\");\n\n\n\n\n\nSingle image. Source: Code by Yujin Pan\n\n\n\n\n\n\n5.1.2.3 Texture measures\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\nMap.addLayer(glcm, {min:14, max: 650}, 'glcm');\n\n\n\n\n\nTexture measures. Source: Code by Yujin Pan\n\n\n\n\n\n\n5.1.2.4 Linear regression\n\nOLS regression\n\nIf we want to see the change over time in pixel values - linearFit()\nlinearFit() takes a least squares approach of one variable. Band 1: dependent variable Band 2: independent variable (often time)\nvar linearFit = collection.select(['dependent variable', 'independent variable']).reduce(ee.Reducer.linearFit());\n\nMuitiple linear regression Create feature sets containing independent and response variables\nFit multiple linear regression using feature sets\nExtracting the coefficients and intercepts of the model\n\n\n\n5.1.2.5 Join\n\njoin\ngeo-join\nintersect For example, this line of code uses the distSaveAll.apply function to calculate the intersection between each point in the powerPlants dataset and each circular buffer in the power_buffer dataset.\n\nvar intersect = distSaveAll.apply(power_buffer, powerPlants, spatialFilter);\nprint(power_buffer, \"power_buffer\");\nMap.addLayer(intersect, {}, 'intersect');\nprint(intersect, \"intersect\");\nSource: Intersect\n\n\n\n5.1.2.6 NDVI\nThis fuction can calculate the NDVI directly.\nvar NDVI = clip.normalizedDifference([SR_B5, SR_B4]);"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\n把这篇文献研究透，多写一点\nMapping of Flood Areas Using Landsat with Google Earth Engine\nThe flood mapping algorithm is presented in this study. The algorithm uses Landsat data to generate historical global flood extent at 30m resolution. Landsat satellite images from 1984 to the present were first collected, pre-processed with layer filtering to classify water bodies, and “temporary” waters were selected as areas that were inundated during the flood event.\n\n\n\n\n\nresearch flow. Source: research flow\n\n\n\n\nThe application of this research has a significant role to play in land use, emergency avoidance. For example，Identifying those locations which are at risk of flooding can allow for optimization of resources and investment such as upgrading infrastructure, developing agriculture, etc., in the short term. On the other hand, this will allow governments, funding agencies and disaster management authorities to drill down to the locations of highest potential risk and generate higher resolution models."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis study is an introduction to CART and its application to remote sensing to solve real urban problems. In practice, I use a supervised learning approach to extract eo data to classify land cover and make a first working task for subsequent analysis such as illegal logging.\n\n6.1.1 CART\nCART is a predictive algorithm used in Machine learning and it explains how the target variable’s values can be predicted based on other matters. It is a decision tree where each fork is split into a predictor variable and each node has a prediction for the target variable at the end.\n\n\n\n\n\nlogic of the machine learning. Source:(https://www.geeksforgeeks.org/ml-types-learning-supervised-learning/?ref=rp)\n\n\n\n\nFollowing process\n\n\n\n\n\nCART Processing\n\n\n\n\n\nThe best split point of each input is obtained.\n\nBased on the best split points of each input in Step 1, the new “best” split point is identified.\n\nSplit the chosen input according to the “best” split point.\n\nContinue splitting until no further desirable splitting is available.\n\n\n6.1.1.1 CART Algorithm\nCART algorithm uses Gini Impurity to split the dataset into a decision tree .It does that by searching for the best homogeneity for the sub nodes, with the help of the Gini index criterion.\n\nThis is the prototype formula.\n\n\n\n\n\nGini\n\n\n\n\nThe degree of the Gini index varies from 0 to 1.\n\nGini=0, all the elements are allied to a certain class, or only one class exists there\nGini=1, all the elements are randomly distributed across various classes\nGini=0.5, the elements are uniformly distributed into some classes.\n\nIn the example “Does someone who loves popcorn or soda love the song cool as ice?”- explained in the lesson, when there is no clear yes or no outcome, then the probabilities of the two choices are calculated and the probabilities of yes and no are brought into the Gini index formula, and if the Gini index is less than 0.5, then it is classified as “yes”.\n\nRestriction\n\nBecause it provides outcomes either “successful” or “failure” and hence conducts binary splitting only and works on categorical variables.\n\n\n6.1.1.2 CART Types\n\n6.1.1.2.1 Classification tree\nThe target variable of the classification tree is categorical. Classification trees are used when the dataset needs to be split into classes that belong to the response variable(like yes or no).\n\nI learned about this is a classification example when filtering emails “spam” or “not spam”, when looking at transaction data, “fraudulent”, or “authorized”.\n\n\n6.1.1.2.2 Regression tree\nThe target variable is continuous and the tree is used to predict its value. Regression trees are used when the response variable is continuous.\nFor example, we can predict future house prices based on the existing house price dataset.\n\nI learned about a case study for analysing the performance of the computer.Here are four attributes relating to main memory: cycle time (MYCT), minimum memory (MMIN), maximum memory (MMAX) and cache (CACH); there are also two attributes relating to channels: minimum channels (CHMIN) and maximum channels (CHMAX). Finally, there is the target: relative performance (PRP).\n\n\n\n\n\nExample of regression tree\n\n\n\n\nThe importance of attributes with respect to predicting the target is reflected in the level at which they are tested within the tree. Therefore, the most predictive attribute is the MMAX in this case.\n\n\n6.1.1.2.3 Difference between the decision and regression tree\n\n\n\n\n\n\n\n\n\nDecision Tree\nRegression Tree\n\n\n\n\nDataset selected\nEither uncontinous or continous data\nmust be continous data\n\n\nHow to divide the tree\nFind segments with a strong majority of a discrete class label\nEmploy splitting metrics based on variance reduction\n\n\nGoal\nClassification\nPredicting the value\n\n\n\n\n\n\n6.1.1.3 CART Assessment\n1.Advantages of CART\nResults are simplistic.\n\nClassification and regression trees are Nonparametric and Nonlinear.\n\nOutliers have no meaningful effect on CART.\n\n2.Limitations of CART\n\nOverfitting\n\n\nOverfitting occurs when the tree takes into account a lot of noise that exists in the data and comes up with an inaccurate result.\n\n\nHigh Variance\n\n\na small variance in the data can lead to a very high variance in the prediction, thereby affecting the stability of the outcome.\n\n\nlow bias\n\n\nA decision tree that is very complex usually has a low bias. This makes it very difficult for the model to incorporate any new data.\n\nHow to tackle the overfitting of the desicion tree?\nreason:the model will correctly classify each and every example if we don’t stop splitting! The training accuracy is 100%\n\nresolution: + Pruning\n\nIt is a technique to remove the parts of the decision tree to prevent growing to its full depth.\n\nRadom Forest\n\n\nIt is a technique for classification and regression by bootstrapping multiple decision trees to prevent overfitting and the random forest can improve the accuracy of the decision tree.\n\n\nThrough watching the vedio, I learned about the approach of the random forest.\n\n1.Create a bootstrapped dataset \n2.Creat a decision tree using the bootstrapped dataset, but only use a random subset of variabled at each step\n\n3.Go back to the step 1 and repeat and will construt a wide variety of trees. The random forest is construted\n\n4.The new data will be input. And the variables will be run down every decision tree,and we can keep track the more votes that is the result of the random forest.\n\n\n6.1.1.4 GEE Practical\nI choose Qinhuangdao city, my hometown, as the study area. After loading the EO data and pre-processing, I choose classify the landcover into water,urban,grass,farm and forest, and make a featurecolection.\n\n// Make a FeatureCollection from the polygons\nvar polygons = ee.FeatureCollection([\n  ee.Feature(water, {'class': 1}),\n  ee.Feature(urban, {'class': 2}),\n  ee.Feature(grass, {'class': 3}),\n  ee.Feature(farm, {'class': 4}),\n  ee.Feature(forest, {'class': 5}),]);\n// Use these bands for classification.\nvar bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7'];\n\nvar classProperty = 'class';\n\n// Sample the composite to generate training data.\nvar training = waytwo_clip.select(bands).sampleRegions({\n  collection: polygons,\n  properties: [classProperty],\n  scale: 10\n});\nprint(training, \"training\")\nAnd I use the CART to classify the image. But it is the basic methods which doesn’t a good accuracy.\n// Train a CART classifier.\nvar classifier = ee.Classifier.smileCart().train({\n  features: training,\n  classProperty: classProperty,\n});\n// Print some info about the classifier (specific to CART).\nprint('CART, explained', classifier.explain());\n\n// Classify the image.\nvar classified = waytwo_clip.classify(classifier);\n\n\nMap.centerObject(qinhuangdao);\nMap.addLayer(classified, {min: 1, max: 5, palette: ['d99282', '466b9f', 'ab0000', 'dfdfc2', 'b3ac9f', '1c5f2c']}, \"classified\");\n\n\n\n\n\nIMAGE BY CART IN QINHUANGDAO\n\n\n\n\nIn order to improve the accuracy of the image, I used the random forest to classification using the picel approach .\nvar pixel_number= 1000;\nvar water_points=ee.FeatureCollection.randomPoints(water, pixel_number).map(function(i){\n  return i.set({'class': 1})})\nvar urban_points=ee.FeatureCollection.randomPoints(urban, pixel_number).map(function(i){\n  return i.set({'class': 2})})\nvar grass_points=ee.FeatureCollection.randomPoints(grass, pixel_number).map(function(i){\n  return i.set({'class': 3})})\nvar farm_points=ee.FeatureCollection.randomPoints(farm, pixel_number).map(function(i){\n  return i.set({'class': 4})})\nvar forest_points=ee.FeatureCollection.randomPoints(forest, pixel_number).map(function(i){\n  return i.set({'class': 5})})\nvar point_sample=ee.FeatureCollection([water_points,\n                                  urban_points,\n                                  grass_points,\n                                  farm_points,\n                                  forest_points])\n                                  .flatten()\n                                  .randomColumn();\n\n// assign 70% of training points to validation \nvar split=0.7\nvar training_sample = point_sample.filter(ee.Filter.lt('random', split));\nvar validation_sample = point_sample.filter(ee.Filter.gte('random', split));\n\n// take samples from image for training and validation  \nvar training = waytwo_clip.select(bands).sampleRegions({\n  collection: training_sample,\n  properties: ['class'],\n  scale: 10,\n});\n\nvar validation = waytwo_clip.select(bands).sampleRegions({\n  collection: validation_sample,\n  properties: ['class'],\n  scale: 10\n});\n\n// Random Forest Classification\nvar rf1_pixel = ee.Classifier.smileRandomForest(100)\n    .train(training, 'class');\n\nprint('Results of RF trained classifier', rf1_pixel.explain());\n\n//  Conduct classification\n    \nvar rf2_pixel = waytwo_clip.classify(rf1_pixel);\n\nMap.addLayer(rf2_pixel, {min: 1, max: 5, \n  palette: ['d99282', '466b9f', 'ab0000', 'dfdfc2', 'b3ac9f', '1c5f2c']},\n  \"RF_pixel\");\n// Assess Accuracy \n\nvar trainAccuracy = rf1_pixel.confusionMatrix();\nprint('Resubstitution error matrix: ', trainAccuracy);\nprint('Training overall accuracy: ', trainAccuracy.accuracy());\n\nvar validated = validation.classify(rf1_pixel);\nvar testAccuracy = validated.errorMatrix('class', 'classification');\nvar consumers=testAccuracy.consumersAccuracy()\n\nprint('Validation error matrix: ', testAccuracy);\nprint('Validation overall accuracy: ', testAccuracy.accuracy())\nprint('Validation consumer accuracy: ', consumers);\n\n\n\n\n\nIMAGE BY RANDOM FOREST IN QINHUANGDAO\n\n\n\n\nthrough both image comparing, I find that the accurancy of classification is improved. Because of observing the urban landcover in the image using the random forest, the urban area locates mainly in coastal areas and urban center.\n\nHowever, this practical has some limitation.I should classify the landcover more clearly, for emaple, the urban with low density, urban with high density, and moutain etc.\n\n\n\n6.1.2 Application\nForest cover change and illegal logging in the Ukrainian Carpathians from 1988 to 2007\nThis paper focuses that the authors’ use Landsat TM/ETM+ imagery and support vector machines (SVM) to derive forest change trajectories across the Ukrainian Carpathians between 1988 and 2007. By mapping forest cover changes and assessing the extent of illegal logging and reforestation in the Ukrainian Carpathians. As a result of the study, the authors found that a general change in forest cover occurred in the Ukrainian Carpathians between 1988 and 2007, mainly in the form of forest decline in the interior of the Carpathians.\n\n\nStudy area: The entire Ukrainian Carpathians\n\n\n\n\n\n\n\nstudy area\n\n\n\n\n\nData collection\n\n\n1.EO data:19 mid-summer and early fall Landsat TM and ETM+ images for ∼ 1988, 1994, ∼ 2000, and ∼ 2007. what’s more，to account for relief displacement, we included the Space Shuttle Topography Mission (SRTM) digital elevation model, resampled to 30 m.\n2.Ground truth data were gathered based on approximately 120 Quickbird images from 2002 to 2007 available in Google Earth, which is comparable to that of the Landsat images. 3.Administrative boundaries at the province (oblast) and district (raion) level were digitized from topographic maps at a scale of 1:100,000 .\n\n\nMethodology: The author used SVM to create forest/non-forest maps for each of the four time periods and assessed forest cover change by comparison of the post-classification maps. After finding the best γ and C, the author classified each of the 19 Landsat TM/ETM+ images according to six multispectral bands. the author divided all available ground truth points into training (90%) and validation (10%) samples. the author classify each image 10 times for all 10 possible segmentations, derive an accuracy metric and then calculate an average error estimate.\nOutput:Forest cover changed substantially in the Ukrainian Carpathians between 1988 and 2007.What’s more, compared with the official forest resource data at the oblast level,The forest cover trends mapped from Landsat imagery differ markedly. Based on official statistics recorded in the Statistical Yearbook of Ukraine, it was found that the relatively high disturbance rates found in the Lvivska and Chernivetska Oblasts prior to 1994 and the significant increase in disturbance rates in the Ivano-Frankivska Oblast after 1988 were not depicted in the forest resource data.\n\n\n\n\n\n\nForest cover changes between 1988 and 2007\n\n\n\n\n\n\n\n\n\nforest resource statistics at the oblast level\n\n\n\n\n\n\n6.1.3 Reflection"
  },
  {
    "objectID": "week5.html#relection",
    "href": "week5.html#relection",
    "title": "5  Google Earth Engine",
    "section": "5.3 Relection",
    "text": "5.3 Relection"
  }
]