[
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Introduction about Remote-sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 The introduction of remote sensing\nRemote sensing collects remotely sensed images by special cameras, which help researchers “sense” things about the earth. And it is that the process of detecting and monitoring the physical characteristics of an area by measuring reflected and emitted radiation from a certain distance.For example, forest fires can be mapped from space, seeing a much larger area than from the ground.\n\n\n1.1.2 Sensor\n\n1.1.2.1 Type\n\n\n\n\n\n\n\nActive sensor\nPassive sensor\n\n\n\n\nUsing light sources from its own\nUsing light sources from the sun\n\n\ncannot penetrate dense cloud cover\npenetrate the atmosphere\n\n\n\n\n\n\n\n\nIn addition, they can also be divided into imaging and non-imaging methods according to the recording method.\nImaging mode sensors represent the intensity of the received electromagnetic wave energy in the form of images, such as aerial cameras, scanners, imaging spectrometers.\nNon-imaging mode sensorsway to detect the intensity of the electromagnetic wave energy of the ground in the form of digital, curved graphical representation, such as radiometer, infrared radiation thermometer.\n\n\n1.1.2.2 Component\n1.Collector: collects the electromagnetic energy from the ground. For example, lenses for aerial cameras, reflectors for scanners, etc.\n2.Detector: converts the collected radiant energy into chemical or electrical energy.\n3.Processors: Process the detected signals, such as chemical or electrical energy. For example, film development and fixing, amplification of electrical signals, filtering, modulation, conversion, etc.\n4.Output: Outputs the images and data obtained. For example, photographic film, magnetic tape recorders, etc.\n\n\n\n\n\nProcessing. Source: From Yujin Pan\n\n\n\n\n\n\n\n1.1.3 Electromagnetic Spectrum\nElectromagnetic energy travels in waves and spans a broad spectrum from very long radio waves to very short gamma rays. The human eye can only detect only a small portion of this spectrum called visible light.\nProtective Atmosphere\nThe atmosphere protects us from a range of high-energy waves that are harmful to life. It likewise absorbs electromagnetic radiation. Among these are mainly water vapour, carbon dioxide and ozone.These regions of the spectrum with wavelengths that can pass through the atmosphere are referred to as “atmospheric windows.” Some microwaves can even pass through clouds, which make them the best wavelength for transmitting satellite communication signals. Because most electromagnetic radiation from space is unable to reach the surface of the Earth, for long-term observations, it is best to have your detector on an orbiting satellite.\n\n\n\n\n\nElectromagnetic Spectrum. Source:(https://science.nasa.gov/ems/01_intro)\n\n\n\n\n\n\n1.1.4 Remotely sensed data\n\nFormat\n\nThe remotely sensed data is raster,mostly GeoTIFF. But LiDAR is the point data.\n\nResolution\n\nResolution has a important role in how data from a sensor can be used. there are four types of resolution to consider for any dataset-radiometric, spatial, spectral, and temporal.\n\n\n\n\n\n\n\n\nResolution Types\nDescription\nExample\n\n\n\n\nspatial\nthe size of the raster grid per pixel\n20cm or 30m\n\n\nspectral\nthe number of bands\nBand 2 - blue (0.45-0.51 wavelength)\n\n\ntemporal\nthe time it revisits\ndaily or every 7 days\n\n\nRadiometric\nthe number of bits representing the energy recorded\n2 bit, 4 bit, or 8 bit"
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Introduction about Remote-sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nRemote sensing has a wide range of applications in many fields. For example, Remote sensing is widely used in agriculture.Traditionally, satellite imagery has been used for crop condition assessment and type mapping of crops, but due to the limited resolution of the sensors, satellites have been used over large areas. With technological advances, finer subscale green can enable remote sensing applications in the field for disaster assessments such as droughts and floods(Wójtowicz M,2016).What’s more, the NDVI index is used most frequently to determine the condition, developmental stages and biomass of cultivated plants and to forecasts their yields. The NDVI has become the most commonly used vegetation index (Wallace et al. 2004, Calvao and Palmeirim 2004).Through the application of remote sensing, producers and governments can prevent natural disasters in advance and minimise economic losses.\n\nRemote sensing also plays an important role in crop yield forecasting. In the Southern Alberta of Canada, for example, remote sensing is used to assess the extent to which the area is vulnerable to drought conditions and to make yield forecasts. This can provide some support for local agricultural planning and reduce economic risk(Xu W,2011).\n\n\nStudy area: Agricultural production in southern Alberta\n\nData selection: In order to assess in detail the vulnerability of agriculture to drought, remotely sensed imagery was used in the empirical analysis. The years 1998, 1999 and 2001 were selected as representative of changes in precipitation conditions. Two Landsat TM/ETM+ images for each selected year were also acquired and overlaid to improve the accuracy of the land use cover.\n\nResearch methodology: In this paper, sensitivity and health status and exposure were selected as the three influencing factors of vulnerability.\nThe first step was to identify crop types using supervised classification to prepare the ground for measuring agricultural vulnerability later. And the NDVI of the image area classified as a cereal crop is used as the main independent variable for yield estimation in the subsequent regression analysis.\nBy calculating the vulnerability coefficient of the crop, the regression is then used to predict the crop yield.\n\n\n\n\n\n\nSpatial distribution of average crop yield (1998,1999, and 2001)\n\n\n\n\n\nComment\n\nThe authors have used remote sensing data to predict crop yields and to analyse the impact of drought on a large area of the region, providing powerful data for local agricultural development. The remote sensing data is available free of charge as open source data, which certainly facilitates agricultural analysis."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Introduction about Remote-sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n1Remote sensing technology has been widely used in many fields, such as environmental protection, geological exploration, weather forecasting, agricultural production and urban planning. It provides us with a wealth of information about the Earth and gives us a better understanding of its changes and evolution.\n2.It can be used to produce a variety of maps and spatial information products such as digital elevation models, vegetation index maps, land use/cover maps, etc. These products can provide accurate descriptions and analyses of the Earth’s surface features.\n3.The rapid development of remote sensing technology has resulted in much lower data acquisition costs and more efficient data processing and analysis. This has allowed an increasing number of institutions and individuals to use remote sensing technology for research and applications.\n4.The applications of remote sensing data in many areas are yet to be further developed, for example, in the field of urban planning and environmental protection, remote sensing data can help us to better assess and predict the impact of urban development and environmental change, and improve the sustainability of cities and the environment.\nThrough this week’s study, I have gained an initial understanding of remote sensing, which I have not studied before. It is useful for me.I have learnt about the types of remote sensors, the format of remote sensing data and the resolution this week. However, my extra-curricular study of remote sensing is far from adequate. I have only studied the application areas of remote sensing in detail from agriculture this week, but I have not studied marine exploration and emergency disaster relief in depth."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Welcome to my learning-diary on remote-sensing."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Introduce about Synthetic Aperture Radar (SAR)",
    "section": "",
    "text": "This is my presentation. Please visit link: https://ucfnyp0.github.io/week2_xaringan/week2.html."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Remote sensing data",
    "section": "3.1 summary",
    "text": "3.1 summary\n\n3.1.1 sensor scanner\nHow to acquire multispectral image data\n\npush broom\n\nCollection method: The detector is perpendicular to the direction of flight of the spacecraft and acquires one image at a time\nData collection: Measure all pixels in a row of images at the same time\nExample:Spot and Orbview\n\n\n\n\n\npush broom. Source:(https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/16262/Push-Broom-and-Whisk-Broom-Sensors)\n\n\n\n\n\nWhisk broom\n\nCollection method: The detector collects the field of view scanned by the detector as the direction of the rotating mirror changes\nData collection: Acquisition of images in a wide range of narrow spectral bands from the visible to mid-infrared spectrum\nExample:Landsat\n\n\n\n\n\nWhisk broom. Source:(https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/16262/Push-Broom-and-Whisk-Broom-Sensors)\n\n\n\n\n\nCompare\n\nA push broom scanner receives a stronger signal than a whisk broom scanner, because it looks at each pixel area for longer.\n\n\n3.1.2 Connection\n\n3.1.2.1 geometric connection\nwhy we need to doing the geometric connection?\n\nView angle (off-nadir)\nNadir means directly down\nTopography (e.g. hills not flat ground)\nWind (if from a plane)\nRotation of the earth (from satellite)\n\nhow we do the geometric connection?\n\nIdentify the GPS\ncompute the geometric transformation coefficients and optain the geographic coordinates\nresample to populate new output grid\n\nRMSE\nThe model with the lowest RMSE will fit best—-always set the value is RMSE\n\nIn order to reduce the PMSE, we need to re-sample the final raster.\nResample methods\n\nNearest Neighbor\nLinear\nCubic\nCubic spline\n\n\n\n\n\n\nre-sample. Source:(https://andrewmaclachlan.github.io/CASA0023-lecture-3/?panelset3=dn2&panelset4=ratio2&panelset5=pca2#23)\n\n\n\n\n\n\n3.1.2.2 Atmospheric correction\nwhy we do the atmospheric connection?\n\nAtmospheric scattering\nTopographic attenuation\n\nAnd in biophysical parameters, we need to do the atmosphere connection. for example, temperature, lead area index, NDVI\nAtmospheric correction types\n\nRelative\n\nNormalize intensities of different bands within a single image and normalize intensities of bands from many dates to one date\n\nAbsolute\n\nuse the atmospheric radiative transfer models to change digital brightness values into scaled reflectance and then compare these scaled surface reflectance values across the planet.\ndata requirements–an atmopsheric model, local atmopsheric visibility, Image altitude\n\n\n3.1.2.3 Orthorectification correction\n\nwhen use the orthorectification correction?\n\nRaw satellite imagery contain distortions, which are induced by sensor orientation, topographical variation and the curvature of the earth.\n\naccurate elevation models are key.\n\nFeature distortion on raw imagery is heavily impacted by terrain variation. An accurate elevation model is required to calculate the effect of terrain variation on the image pixels.\n\n\n3.1.2.4 Radiometric Calibration\nRadiometric calibration is a crucial part of processing multispectral imagery, it enables the conversion of raw digital numbers (from the raw imagery), to sensor reflectance or irradiance, and then to surface reflectance values. Using a radiometric workflow enables the collection of repeatable reflectance data over different flights, dates, and weather conditions.\nWithout radiometric calibration, you may see the following effects:\n\nUnderexposed images, especially surrounding bright objects on the landscape\nIrregular coloration\nIndex values, such as NDVI, that appear to change dramatically and unexpectedly + near roads or buildings\nExtreme banding or patchiness in the mosaic"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Remote sensing data",
    "section": "3.2 Application",
    "text": "3.2 Application\nMultispectral UAS Data Accuracy for Different Radiometric Calibration Methods  The performance of five radiometric calibration methods commonly used was investigated in this study. Multispectral imagery was collected using a Parrot Sequoia camera. Unmanned aircraft systems (UAS) allow us to collect aerial data at high spatial and temporal resolution in this study. And radiometric calibration is an essential step of UAS data processing, mainly when imagery is acquired for the analysis of biophysical processes, to monitor a study area over time, and to compare different sensors .The five methods are one-point calibration (method A), one-point calibration plus sunshine sensor (method B), pre-calibration using the simplified empirical line calibration (method C) , one-point calibration plus sunshine sensor plus post-calibration(method D), and post-calibration using the simplified empirical line calibration (method E). The paper found there are no method that can have the best performance in every band.\nThrough comparing the five methods, there are the RmsE values.\n\n\n\n\n\nRoot-mean-square error (RMSE) values\n\n\n\n\nThrough the RMSE values for each calibration method, the author found the following results. Data accuracy varied between the multispectral bands (Figure 7). For methods B and E, pixel reflectance values were more accurate in the red-edge and NIR band than in the green and red bands. For method D, pixel reflectance values were more accurate in the NIR and red-edge bands than in the green and red bands. Maximum differences between bands were observed for methods B and D. Minimum differences were observed for method E, closely followed by method C.\n\n\n\n\n\nDistribution of root-mean-square error (RMSE) values for each calibration method\n\n\n\n\nOn average, method D minimized error across bands and grey values closely followed by method E. Method D resulted in better data accuracy than method B, and results indicated that data quality provided by the manufacturer-recommended calibration could be further improved with an empirical calibration. Method E resulted in better data accuracy than method C, and results showed that calibrating the processed uncalibrated rasters would be preferable to calibrating the raw images before data processing. Method A provided lower data accuracy than the other four methods in the green, red, and red-edge bands. Method A failed to calibrate acquired imagery in the NIR band. The result is that there are no method that can have the best performance in every band.\n\nMultispectral UAS Data Accuracy for Different Radiometric Calibration Methods \nWhat’s more, about the geometric connection,this paper shows the geometric correction process done in the Coimbatore imagery to improve the quality and it shows the process of distortion removed .Finally they get the georectified image using ERDAS(Baboo and Devi, 2011).\nA geometric correction of the image is required whenever the image is to be compared with existing maps or with other images. The goal of image rectification is to facilitate the overlay of additional imagery and other geographic data sets. A standard map area, with boundaries set in UTM, is established for each scene, thus all image files for the same region, once rectified, will occupy the same map area.Once the raw remote sensing digital data has been acquired, it is then processed into usable information.Processing digital data involves changing the data to correct for certain types of distortions. Whenever data is changed to correct for one type of distortion, the possibility of the creating another type of distortion exists. There is an example to show the importance on the pre-processing.Because the Coordinates not in British National Grid coordinates.\n\n\n\n\n\nGeometrically not corrected Coimbatore Imagery\n\n\n\n\nThe below Figure explain the image to map geocorrection and we can see the ground control point spread all over the map.Right side of the image is study area of the Coimbatore toposheets.Adding GCP from a map is easy and straightforward. However, care should be taken when choosing the correct position of a GCP, as a scanned map might add to the RMS error, because roads tend to be drawn wider than they actually are, or even slightly displaced, i.e.University Road is said to be approximately 30m wide. In addition, the pixel size of the map is 3m; the image itself operates with 30m, which is another source of error in correct placement of GCP.\n\n\n\n\n\nGeocorrection using Coimbatore imagery and Coimbatore Toposheet"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Remote sensing data",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nIn this week’s study, I learnt about remote scanners and calibration, among other things. Before using remote sensing data, we have to carry out data pre-processing, such as atmospheric correction, to eliminate the influence of atmospheric medium on the brightness value of remote sensing images, so that the remote sensing images reflect the real surface reflectance of the features, which can provide the basic data for the subsequent extraction and application of remote sensing information. What’s more, geometric correction of remote sensing is a fundamental step in remote sensing image processing and an important link in the application of remote sensing technology. Through geometric correction, accurate correspondence can be established between remote sensing images in terms of spatial position and actual ground position, providing basic data for remote sensing information extraction and application."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "::: {#refs} ::: {#refs Baboo, Dr.S.S., Devi, M.R., 2011. Geometric Correction in Recent High Resolution Satellite Imagery: A Case Study in Coimbatore, Tamil Nadu. IJCA 14, 32–37. https://doi.org/10.5120/1808-2324}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary for CASA0023",
    "section": "",
    "text": "Preface\nWelcome to my learning diary for CASA0023!\nMy name is Yujin Pan. I graduated from in China with a Bachelor’s degree in Urban and Rural Planning.My research interests are mainly in the areas of spatial accessibility and urban public facilities optimisation, and I hope that my postgraduate studies will enable me to understand and learn more about the rich and advanced technologies that guide my studies and work on urban planning.\nThanks to Andy for guiding me and the course!"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\nstudy city:New York\n\nstudy policy: OneNYC 2050\n\nstudy topic: urban heated island\n\n\n\n\n\n\nOneNYC2050. Source: OneNYC 2050\n\n\n\n\n\n4.1.1 Background of Policy\nClimate change is a growing crisis for cities. High temperatures, on the other hand, are one of the most important aspects of the climate crisis, which has become the number one cause of death due to weather conditions in the United States. By the 2050s, the average temperature in New York City is expected to rise by 5.7 degrees Fahrenheit, and up to 1,500 people will die each summer from the heat.\n\n\n4.1.2 Specific Policy\nglobal policy : The Paris Agreement\nThe global response to the threat of climate change should be strengthened by achieving carbon neutrality and aggressive reductions in greenhouse gas emissions as soon as possible.\nMetropolitan policy: OneNYC 2050: VOLUME 7 OF 9- A LIVABLE CLIMATE\n\nCreating a liveable climate, responding positively to the Paris Agreement, taking action on climate change, especially for the most vulnerable communities, and upholding climate justice\nCommit to a just transition to carbon neutrality, climate resilience and a clean economy to improve environmental quality for all and redressing injustices\nInvest in infrastructure that mitigates climate risks, such as vegetation planting Forge partnerships on climate solutions across communities, sectors and regions to share the benefits\n\nCase:Shi Jiazhuang\nThis study was carried out using Landsat TM images at the mesoscale level and airborne hyperspectral thermal imagery at the microscale level. Surface temperatures (LST) were inferred from four scenes of summer Landsat TM data to analyse the thermal spatial pattern and intensity of the surface UHI (SUHI). And to describe more detailed urban thermal characteristics of the center of Shijiazhuang from TASI data.\nThe authors obtained the impervious variable area from EO data,and in order to investigate the intrinsic relationship between impervious density distribution and urban thermal patterns, classified the urban landscape into different categories based on impervious density. And to obtain the surface temperature. And to obtain land surface cover patterns using SVM machine learning methods using Landsat and TASI.\nBy comparing the two maps of land cover type and surface temperature, it was found that there is a strong relationship between impervious land cover and high surface temperature.\n\n\n\n\n\n\npercent impervious surface area distribution\n\n\n\n\n\n\n\n\n\nLST distribution\n\n\n\n\nAnd in order to study the relationship between urban spatial pattern and thermal radiation at microscopic scale, the land cover types ambient concrete built-up area, water body, bare soil, vegetation, and mixed asphalt were used to represent different spatial attributes.\n\n\n\n\n\nLCTs map in the center\n\n\n\n\nConcerning the time phase of early morning, the temperature differences among various urban covers were smaller compared to other periods of time (noon and evening). Most land cover had a relatively similar thermal response at this time, and their surface temperature differences were minimal. For the noon and evening, as can be clearly seen, the most important surface components contributing heat to urban areas were rooftops, asphalt, and concrete which have lower thermal inertia. Contrary to the morning, water and vegetation area had lower temperatures during the noon. When it came to the evening, the temperature of impervious surface and bare soil was still higher than other cover types due to significantly different thermal bulk properties.\nWhat’s more, this study suggests that careful consideration is required for land use planning, particularly in urban–suburb areas where a widespread change in LCTs can significantly impact thermal responses. Urban planners attempting to mitigate the negative impact of urban sprawl on urban heat island should give serious consideration to both the area percentage of various land-cover types and their spatial distribution as well.\nComment\nThis paper uses analysis of the suhi effect by analysing the effect of land cover type on surface temperature, and uses multi-temporal airborne thermal imagery to analyse detailed urban thermal characteristics of urban centres. In terms of data set acquisition, landsat is useful for studying the suhi effect at the mesoscopic scale, but it is not clear which specific surfaces contribute to the extent of the heat island effect. For high-resolution satellite data, further acquisition is needed by means of high-resolution data acquisition to delve into the urban heat island problem in Shijiazhuang."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nIn this part, i will concern about how to use the EO data to resolve the urban heated island. In the following, there are one case and one reading to explain.\n\n4.2.1 Major Summer Heat Spots using Landsat-8 Thermal Satellite data\n\nData Collection\n\nEarth observation data- the Landsat8 data in summer\nOpen street map- the great London\n\nData Analysis\n\nTo generate a dataset that presents the LST spatial distribution and the corresponding hotspots for GLA, a five-year (2016-2020) time series of satellite-derived 100 m daytime LST images (in °C) is employed. The utilized data correspond only to summer months (i.e. June, July and August) so as to capture the hotspots with the most important impact on thermal discomfort, human health and energy demand.\nIn addition to the average LST (avgLST), the avgLST standard deviation, minimum and maximum for each city block are also estimated.\nFinally, the former statistics are stored as new attributes in the Urban Atlas polygons and the updated vectors are then exported as a new shapefile.\n\nOutput\n\n\n\n\n\n\nGeopackage. Source: Methodology and Deliverables Report_LONDON_ARTi\n\n\n\n\n\n\n\n\n\nGeopackage. Source: Methodology and Deliverables Report_LONDON_ARTi\n\n\n\n\n\n\n4.2.2 Social Inequities in Urban Heat and Greenspace: Analyzing Climate Justice in Delhi,India\nThis study quantifies exposure through the Urban Heat Risk Index (UHRI) and proximity to green spaces through the Normalised Difference Vegetation Index (NDVI) at ward level in Delhi to consider the urban social The distribution of inequalities in terms of burdens and benefits.\n\nthe dependent variable\n\nHeat exposure was estimated using the urban heat risk index (UHRI), a composite index of biophysical factors related to urban heat.And the equation is UHRI = [LST (z score) + NDBI (z score)] − NDVI (z score).\n\nLST is the land surface temperature, which is calculated from the Landsat data. NDBI was assessed by calculating the NDVI (normalized difference vegetation index). The UHRI thus takes all three into account as an indication of the spatial extent and intensity of the urban heat island.\n\n\n\n\n\nUHRI & NDVI. Source: Social Inequities in Urban Heat and Greenspace: Analyzing Climate Justice in Delhi,India\n\n\n\n\n\nthe independent variable\nsocio-demographic vulnerability, denoted by children, caste, and family size\nhousing-related vulnerability, denoted by household access to assets, electricity,and home ownership\nemployment-related vulnerability, denoted by literacy and involvement in agriculture\nthe output\n\n\n\n\n\n\nGeneralized estimating equation for predicting May UHRI using ward level socio-demographic variables. Source: Social Inequities in Urban Heat and Greenspace: Analyzing Climate Justice in Delhi,India\n\n\n\n\nThe UHRI is significantly positively associated with the proportion of children, SC, agricultural workers, households with assets and households with electricity (p < 0.01), but negatively associated (p < 0.005) with the proportion of educated residents, households that own a home and larger households(Liu et al. 2015).\n\nThrough correlation analysis and spatial visualisation of areas with high heat exposure indices, government funding for social vulnerability related factors such as households with severe poverty and electricity, schools, in addition to focusing not only on the heat island environment in the central city, it was shown through the strong correlation between agricultural labour and NDVI that the government should also focus on the population in the urban periphery. The correlation study aims to make a valuable contribution to the integration of climate justice considerations into climate change planning in Delhi by demonstrating which vulnerable groups should be prioritised in the policy if the urban heated island."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThrough the focus on high temperatures in the New York City 2050 plan, I have focused my attention on urban heat island issues, hoping to disentangle and propose specific strategies for 2050 planning goals through remote sensing data analysis, rather than macro planning. An example is the delivery of the UK Hotspot Toolkit. Through the collection of EO data, SUHI data is obtained and spatially visualised to give the government and citizens a clear picture of the hotspots that need to be focused on, providing specific geographical information on the location of the next solutions to the urban heat island problem. The Indian literature, on the other hand, provides possible correlates for addressing climate equity and can assist the government in providing direction for addressing equity issues. However, I believe that the current work is still far from adequate and that workflows need to be proposed for New York to mitigate the urban heat island problem and achieve climate equity, such as how to green the infrastructure and how to conduct urban temperature implementation monitoring.\n\n\n\n\nLiu, Kai, Hongbo Su, Lifu Zhang, Hang Yang, Renhua Zhang, and Xueke Li. 2015. “Analysis of the Urban Heat Island Effect in Shijiazhuang, China Using Satellite and Airborne Data.” Remote Sensing 7 (4): 4804–33. https://doi.org/10.3390/rs70404804."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Introduction to the Google Earth Engine\nGoogle Earth Engine combines data from hundreds of satellites and Earth observation datasets with powerful cloud computing to display high-resolution, timely and accurate remote sensing information, providing a platform for remote sensing data analysis.\nStrength: It permits geospatial analysis at scale + massive datasets + planetary scale analysis + quickly (within seconds)\n\n\n5.1.2 How to use the GEE\n\nuse the javascript code\nvar to define the variable\nee to acquire the EO data\nsome items\nGeometry : point/line/polygon with no attributes\nFeature : geometry with attributes\nFeature collection : several features with attributes, and it can be used for the storage, querying, analysis and visualisation of geographical information.\nImageCollection : A collection of multiple satellite images (Images). These images can be from different times, sensors, resolutions etc. They can be used to study different surface features such as vegetation cover, land use, climate change,eg:ee.ImageCollection(‘LANDSAT/LC08/C02/T1_L2’)\n\n\n\n\n\n\n\nCommon Earth Engine object classes. Source: GEE\n\n\n\n\n\n5.1.2.1 Set the Geometry\n//select the point\nvar point = ee.Geometry.Point([108.95000, 34.26667])\nMap.centerObject(Xian, 10)\n\n\n5.1.2.2 Load and filter the EO data\nvar oneimage_study_area_cloud = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n.filterDate('2019-01-01', '2022-12-10')\n.filterBounds(xian)  // Intersecting ROI\n.filter(ee.Filter.lt(\"CLOUD_COVER\", 0.1));\n\n\n\n\n\nXian. Source: Code by Yujin Pan\n\n\n\n\nIt shows the band information of landsat8 in the “Inspector”\n\n\n\n\n\nBand Information. Source: Code by Yujin Pan\n\n\n\n\nLoad the single image\n“127036” represents the longitude and latitude, and “20220517” represents the date I want to acquire.\nvar image = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_127036_20220517')\nvar rgbvis = {\n  bands: ['SR_B4','SR_B3','SR_B2'],\n  min: 5000,\n  max: 15000};\nMap.addLayer(image,rgbvis,\"landsat8\");\n\n\n\n\n\nSingle image. Source: Code by Yujin Pan\n\n\n\n\n\n\n5.1.2.3 Texture measures\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\nMap.addLayer(glcm, {min:14, max: 650}, 'glcm');\n\n\n\n\n\nTexture measures. Source: Code by Yujin Pan\n\n\n\n\n\n\n5.1.2.4 Linear regression\n\nOLS regression\n\nIf we want to see the change over time in pixel values - linearFit()\nlinearFit() takes a least squares approach of one variable. Band 1: dependent variable Band 2: independent variable (often time)\nvar linearFit = collection.select(['dependent variable', 'independent variable']).reduce(ee.Reducer.linearFit());\n\nMuitiple linear regression Create feature sets containing independent and response variables\nFit multiple linear regression using feature sets\nExtracting the coefficients and intercepts of the model\n\n\n\n5.1.2.5 Join\n\njoin\ngeo-join\nintersect For example, this line of code uses the distSaveAll.apply function to calculate the intersection between each point in the powerPlants dataset and each circular buffer in the power_buffer dataset.\n\nvar intersect = distSaveAll.apply(power_buffer, powerPlants, spatialFilter);\nprint(power_buffer, \"power_buffer\");\nMap.addLayer(intersect, {}, 'intersect');\nprint(intersect, \"intersect\");\nSource: Intersect\n\n\n\n5.1.2.6 NDVI\nThis fuction can calculate the NDVI directly.\nvar NDVI = clip.normalizedDifference([SR_B5, SR_B4]);"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nMapping of Flood Areas Using Landsat with Google Earth Engine\nThe flood mapping algorithm is presented in this study. The algorithm uses Landsat data to generate historical global flood extent at 30m resolution. Landsat satellite images from 1984 to the present were first collected, pre-processed with layer filtering to classify water bodies, and “temporary” waters were selected as areas that were inundated during the flood event.\n\n\n\n\n\nresearch flow. Source: research flow\n\n\n\n\nThe application of this research has a significant role to play in land use, emergency avoidance. For example，Identifying those locations which are at risk of flooding can allow for optimization of resources and investment such as upgrading infrastructure, developing agriculture, etc., in the short term. On the other hand, this will allow governments, funding agencies and disaster management authorities to drill down to the locations of highest potential risk and generate higher resolution models."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis study is an introduction to CART and its application to remote sensing to solve real urban problems. In practice, I use a supervised learning approach to extract eo data to classify land cover and make a first working task for subsequent analysis such as illegal logging.\n\n6.1.1 CART\nCART is a predictive algorithm used in Machine learning and it explains how the target variable’s values can be predicted based on other matters. It is a decision tree where each fork is split into a predictor variable and each node has a prediction for the target variable at the end.\n\n\n\n\n\nlogic of the machine learning. Source:(https://www.geeksforgeeks.org/ml-types-learning-supervised-learning/?ref=rp)\n\n\n\n\nFollowing process\n\n\n\n\n\nCART Processing\n\n\n\n\n\nThe best split point of each input is obtained.\n\nBased on the best split points of each input in Step 1, the new “best” split point is identified.\n\nSplit the chosen input according to the “best” split point.\n\nContinue splitting until no further desirable splitting is available.\n\n\n6.1.1.1 CART Algorithm\nCART algorithm uses Gini Impurity to split the dataset into a decision tree .It does that by searching for the best homogeneity for the sub nodes, with the help of the Gini index criterion.\n\nThis is the prototype formula.\n\n\n\n\n\nGini\n\n\n\n\nThe degree of the Gini index varies from 0 to 1.\n\nGini=0, all the elements are allied to a certain class, or only one class exists there\nGini=1, all the elements are randomly distributed across various classes\nGini=0.5, the elements are uniformly distributed into some classes.\n\nIn the example “Does someone who loves popcorn or soda love the song cool as ice?”- explained in the lesson, when there is no clear yes or no outcome, then the probabilities of the two choices are calculated and the probabilities of yes and no are brought into the Gini index formula, and if the Gini index is less than 0.5, then it is classified as “yes”.\n\nRestriction\n\nBecause it provides outcomes either “successful” or “failure” and hence conducts binary splitting only and works on categorical variables.\n\n\n6.1.1.2 CART Types\n\n6.1.1.2.1 Classification tree\nThe target variable of the classification tree is categorical. Classification trees are used when the dataset needs to be split into classes that belong to the response variable(like yes or no).\n\nI learned about this is a classification example when filtering emails “spam” or “not spam”, when looking at transaction data, “fraudulent”, or “authorized”.\n\n\n6.1.1.2.2 Regression tree\nThe target variable is continuous and the tree is used to predict its value. Regression trees are used when the response variable is continuous.\nFor example, we can predict future house prices based on the existing house price dataset.\n\nI learned about a case study for analysing the performance of the computer.Here are four attributes relating to main memory: cycle time (MYCT), minimum memory (MMIN), maximum memory (MMAX) and cache (CACH); there are also two attributes relating to channels: minimum channels (CHMIN) and maximum channels (CHMAX). Finally, there is the target: relative performance (PRP).\n\n\n\n\n\nExample of regression tree\n\n\n\n\nThe importance of attributes with respect to predicting the target is reflected in the level at which they are tested within the tree. Therefore, the most predictive attribute is the MMAX in this case.\n\n\n6.1.1.2.3 Difference between the decision and regression tree\n\n\n\n\n\n\n\n\n\nDecision Tree\nRegression Tree\n\n\n\n\nDataset selected\nEither uncontinous or continous data\nmust be continous data\n\n\nHow to divide the tree\nFind segments with a strong majority of a discrete class label\nEmploy splitting metrics based on variance reduction\n\n\nGoal\nClassification\nPredicting the value\n\n\n\n\n\n\n6.1.1.3 CART Assessment\n1.Advantages of CART\nResults are simplistic.\n\nClassification and regression trees are Nonparametric and Nonlinear.\n\nOutliers have no meaningful effect on CART.\n\n2.Limitations of CART\n\nOverfitting\n\n\nOverfitting occurs when the tree takes into account a lot of noise that exists in the data and comes up with an inaccurate result.\n\n\nHigh Variance\n\n\na small variance in the data can lead to a very high variance in the prediction, thereby affecting the stability of the outcome.\n\n\nlow bias\n\n\nA decision tree that is very complex usually has a low bias. This makes it very difficult for the model to incorporate any new data.\n\nHow to tackle the overfitting of the desicion tree?\nreason:the model will correctly classify each and every example if we don’t stop splitting! The training accuracy is 100%\n\nresolution: + Pruning\n\nIt is a technique to remove the parts of the decision tree to prevent growing to its full depth.\n\nRadom Forest\n\n\nIt is a technique for classification and regression by bootstrapping multiple decision trees to prevent overfitting and the random forest can improve the accuracy of the decision tree.\n\n\nThrough watching the vedio, I learned about the approach of the random forest.\n\n1.Create a bootstrapped dataset \n2.Creat a decision tree using the bootstrapped dataset, but only use a random subset of variabled at each step\n\n3.Go back to the step 1 and repeat and will construt a wide variety of trees. The random forest is construted\n\n4.The new data will be input. And the variables will be run down every decision tree,and we can keep track the more votes that is the result of the random forest.\n\n\n6.1.1.4 GEE Practical\nI choose Qinhuangdao city, my hometown, as the study area. After loading the EO data and pre-processing, I choose classify the landcover into water,urban,grass,farm and forest, and make a featurecolection.\n\n// Make a FeatureCollection from the polygons\nvar polygons = ee.FeatureCollection([\n  ee.Feature(water, {'class': 1}),\n  ee.Feature(urban, {'class': 2}),\n  ee.Feature(grass, {'class': 3}),\n  ee.Feature(farm, {'class': 4}),\n  ee.Feature(forest, {'class': 5}),]);\n// Use these bands for classification.\nvar bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7'];\n\nvar classProperty = 'class';\n\n// Sample the composite to generate training data.\nvar training = waytwo_clip.select(bands).sampleRegions({\n  collection: polygons,\n  properties: [classProperty],\n  scale: 10\n});\nprint(training, \"training\")\nAnd I use the CART to classify the image. But it is the basic methods which doesn’t a good accuracy.\n// Train a CART classifier.\nvar classifier = ee.Classifier.smileCart().train({\n  features: training,\n  classProperty: classProperty,\n});\n// Print some info about the classifier (specific to CART).\nprint('CART, explained', classifier.explain());\n\n// Classify the image.\nvar classified = waytwo_clip.classify(classifier);\n\n\nMap.centerObject(qinhuangdao);\nMap.addLayer(classified, {min: 1, max: 5, palette: ['d99282', '466b9f', 'ab0000', 'dfdfc2', 'b3ac9f', '1c5f2c']}, \"classified\");\n\n\n\n\n\nIMAGE BY CART IN QINHUANGDAO\n\n\n\n\nIn order to improve the accuracy of the image, I used the random forest to classification using the picel approach .\nvar pixel_number= 1000;\nvar water_points=ee.FeatureCollection.randomPoints(water, pixel_number).map(function(i){\n  return i.set({'class': 1})})\nvar urban_points=ee.FeatureCollection.randomPoints(urban, pixel_number).map(function(i){\n  return i.set({'class': 2})})\nvar grass_points=ee.FeatureCollection.randomPoints(grass, pixel_number).map(function(i){\n  return i.set({'class': 3})})\nvar farm_points=ee.FeatureCollection.randomPoints(farm, pixel_number).map(function(i){\n  return i.set({'class': 4})})\nvar forest_points=ee.FeatureCollection.randomPoints(forest, pixel_number).map(function(i){\n  return i.set({'class': 5})})\nvar point_sample=ee.FeatureCollection([water_points,\n                                  urban_points,\n                                  grass_points,\n                                  farm_points,\n                                  forest_points])\n                                  .flatten()\n                                  .randomColumn();\n\n// assign 70% of training points to validation \nvar split=0.7\nvar training_sample = point_sample.filter(ee.Filter.lt('random', split));\nvar validation_sample = point_sample.filter(ee.Filter.gte('random', split));\n\n// take samples from image for training and validation  \nvar training = waytwo_clip.select(bands).sampleRegions({\n  collection: training_sample,\n  properties: ['class'],\n  scale: 10,\n});\n\nvar validation = waytwo_clip.select(bands).sampleRegions({\n  collection: validation_sample,\n  properties: ['class'],\n  scale: 10\n});\n\n// Random Forest Classification\nvar rf1_pixel = ee.Classifier.smileRandomForest(100)\n    .train(training, 'class');\n\nprint('Results of RF trained classifier', rf1_pixel.explain());\n\n//  Conduct classification\n    \nvar rf2_pixel = waytwo_clip.classify(rf1_pixel);\n\nMap.addLayer(rf2_pixel, {min: 1, max: 5, \n  palette: ['d99282', '466b9f', 'ab0000', 'dfdfc2', 'b3ac9f', '1c5f2c']},\n  \"RF_pixel\");\n// Assess Accuracy \n\nvar trainAccuracy = rf1_pixel.confusionMatrix();\nprint('Resubstitution error matrix: ', trainAccuracy);\nprint('Training overall accuracy: ', trainAccuracy.accuracy());\n\nvar validated = validation.classify(rf1_pixel);\nvar testAccuracy = validated.errorMatrix('class', 'classification');\nvar consumers=testAccuracy.consumersAccuracy()\n\nprint('Validation error matrix: ', testAccuracy);\nprint('Validation overall accuracy: ', testAccuracy.accuracy())\nprint('Validation consumer accuracy: ', consumers);\n\n\n\n\n\nIMAGE BY RANDOM FOREST IN QINHUANGDAO\n\n\n\n\nthrough both image comparing, I find that the accurancy of classification is improved. Because of observing the urban landcover in the image using the random forest, the urban area locates mainly in coastal areas and urban center.\n\nHowever, this practical has some limitation.I should classify the landcover more clearly, for emaple, the urban with low density, urban with high density, and moutain etc.\n\n\n\n6.1.2 Application\nForest cover change and illegal logging in the Ukrainian Carpathians from 1988 to 2007\nThis paper focuses that the authors’ use Landsat TM/ETM+ imagery and support vector machines (SVM) to derive forest change trajectories across the Ukrainian Carpathians between 1988 and 2007. By mapping forest cover changes and assessing the extent of illegal logging and reforestation in the Ukrainian Carpathians. As a result of the study, the authors found that a general change in forest cover occurred in the Ukrainian Carpathians between 1988 and 2007, mainly in the form of forest decline in the interior of the Carpathians.\n\n\nStudy area: The entire Ukrainian Carpathians\n\n\n\n\n\n\n\nstudy area\n\n\n\n\n\nData collection\n\n\n1.EO data:19 mid-summer and early fall Landsat TM and ETM+ images for ∼ 1988, 1994, ∼ 2000, and ∼ 2007. what’s more，to account for relief displacement, we included the Space Shuttle Topography Mission (SRTM) digital elevation model, resampled to 30 m.\n2.Ground truth data were gathered based on approximately 120 Quickbird images from 2002 to 2007 available in Google Earth, which is comparable to that of the Landsat images. 3.Administrative boundaries at the province (oblast) and district (raion) level were digitized from topographic maps at a scale of 1:100,000 .\n\n\nMethodology: The author used SVM to create forest/non-forest maps for each of the four time periods and assessed forest cover change by comparison of the post-classification maps. After finding the best γ and C, the author classified each of the 19 Landsat TM/ETM+ images according to six multispectral bands. the author divided all available ground truth points into training (90%) and validation (10%) samples. the author classify each image 10 times for all 10 possible segmentations, derive an accuracy metric and then calculate an average error estimate.\nOutput:Forest cover changed substantially in the Ukrainian Carpathians between 1988 and 2007.What’s more, compared with the official forest resource data at the oblast level,The forest cover trends mapped from Landsat imagery differ markedly. Based on official statistics recorded in the Statistical Yearbook of Ukraine, it was found that the relatively high disturbance rates found in the Lvivska and Chernivetska Oblasts prior to 1994 and the significant increase in disturbance rates in the Ivano-Frankivska Oblast after 1988 were not depicted in the forest resource data.\n\n\n\n\n\n\nForest cover changes between 1988 and 2007\n\n\n\n\n\n\n\n\n\nforest resource statistics at the oblast level\n\n\n\n\nComment\nThe authors chose svm as the analysis method, which can better handle large-scale datasets and has the ability to handle complex data, making it a better analysis method for monitoring image classification such as illegal logging activities in forest areas. The authors also consider the influence of population activity and DEM on forest monitoring disturbances with rigour. However, in this article, large-scale natural disturbances are not taken into account, such as more frequent storms in the local area, or insect infestations, which can bias the data analysis results to some extent.\n\n\n6.1.3 Reflection\nThrough this week, I have learnt about the power of machine learning in the field of remote sensing, especially in land cover classification. And through extra-curricular literature reading and practical application, I realised the wide application of random forests. Firstly, random forests can handle the high-dimensional data contained in remote sensing data, and it has strong stability to avoid the drawbacks of over-fitting simple classification trees.\n\nIn addition, in reviewing the data, he found that land cover classification can also be performed by deep learning methods. He trained a deep neural network for classification through a large amount of data. In remote sensing image classification, deep learning can use convolutional neural networks (CNNs) to extract and classify spatial features in images. This is an area that I am not currently exposed to and have developed an interest in myself, so I hope to learn something about it later."
  },
  {
    "objectID": "week5.html#relection",
    "href": "week5.html#relection",
    "title": "5  Google Earth Engine",
    "section": "5.3 Relection",
    "text": "5.3 Relection\nThrough this week, I have learnt about the powerful remote sensing data analysis capabilities of GEE and have learnt the basic operation of the GEE platform. Reading through the literature the GEE platform can help decision makers in urban related professional fields to better understand the dynamics of urban development. Through remote sensing technology, changes in urban development can be monitored in real time, including changes in urban sprawl, building heights, traffic flow, etc. This information can provide strong data to support urban planning and policy. For example, to review the analysis of the New York heat island problem in week four, we can use the GEE and landsat remote sensing datasets to visualise and analyse the temperature of New York City and calculate the heat island intensity, I have accessed the relevant code materials and read them, which will be of great help to me in my subsequent report."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Urban Heated Island",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Background\nVarious problems will accompany rapid urban development. Many cities, especially megacities, are facing problem caused by urbanization. Because of urban sprawl, Urban Heat Island (UHI) phenomenon expanded.\n\n\n8.1.2 What is the UHI\nUHI means any urban area which is significantly hotter than the neighboring area. Urban heat island is highly noticeable during winter and summer periods, and the temperature difference is often greater at night than in the daytime.\n\n\n\n\n\nUHI\n\n\n\n\n\n\n8.1.3 Reason for the UHI\n1.Low Albedo Materials.It depends on the arrangement of surfaces, materials, pavements, coatings, etc. Albedo has a direct impact on the formation of the microclimate.\n2.Paved and Impermeable Surfaces.Paved over surfaces, such as roads and parking lots, can absorb solar radiation as heat, and these surfaces are typically impermeable,\n3.Thermal Mass.Buildings contain a lot of thermal mass, which means they store a lot of heat during the day and are slow to release the heat overnight.\n4.Lack of VegetationForests are wiped out on a massive scale to meet the demand of various urban facilities. Lesser trees mean less cooling efficiency.\n5.Human Gathering.As human gathering is huge at the city centers owing to the availability of various facilities, the emission of CO2 is also huge in these areas. CO2 stores heat, causing enhanced atmospheric temperature. The ultimate effect is that it assists in the formation of heat island to a great extent.\n\n\n8.1.4 Impact for the UHI\n1.Climate\nBesides the high-temperature increases, urban heat island (UHIs) can bring forth secondary effects on the local weather and climate. This includes changes in local wind patterns, the formation of fog and clouds, precipitation rates and humidity.\n2.Health\nHuman health is negatively impacted because of increased general discomfort, exhaustion, heat-related mortality, headaches, heat stroke and heat cramps.\n3.Economic\nIncreased temperatures during summer in cities amplify energy demand for air conditioning.\n4.Environment\nUHI raises electricity demand during summer. As a result, power plants have to supply the needed extra energy, and since they rely on fossil fuel for energy production, there is an increase in greenhouse gas emissions and air pollution.\n\n\n8.1.5 Case about how to resolve the problem with UHI\n\n8.1.5.1 City level– Cities100: Medellín’s interconnected green corridors\n\n\n\n\n\nGreen Corridors\n\n\n\n\nSince 2016, Medellín has created 30 “Corredores Verdes”, an interconnected green network throughout the city. This action further connects existing green spaces, improves the biodiversity of the city and reduces the urban heat island effect of the city. By planting a large number of trees in the city, air pollutants are absorbed and have a profound impact on the local urban environment.\nSpecifically, the city employs people to train as urban gardeners and planting technicians to plant a number of trees. Nearly 10,000 trees have since been planted along 30 corridors. These green corridors provide Medellín with a large number of ecosystem services: they help to reduce the city’s average temperature by 2°C, achieve carbon sequestration through plant growth, capture particulate matter (PM2.5) to improve air quality, and increase the city’s biodiversity by creating more wildlife-friendly habitats.\n\n\n8.1.5.2 Neighbor level– the Climate Street in Amsterdam\nOne of Amsterdam’s initiatives as an international model of a sustainable city is the Climate Streets. It aims to achieve CO2 reduction and environmental protection in the streets.\n\n\n\n\n\n\nClimate street\n\n\n\n\nThe project focuses on the deep night light automatic attenuation device, and the built-in garbage compression equipment is installed in the solar BigBelly garbage bin, which is a 35-fold increase in the garbage bin space recovery rate. The plan also installs smart meters in merchants along the street to connect them to energy-efficient appliances. Expert Ke can keep abreast of energy consumption through the energy visual screen, and can reduce or turn off unused household appliances or electric lights based on smart meters.Merchants can also get a chance to enjoy preferential protection when purchasing energy-saving appliances or energy-saving lamps after providing an energy bill to the Energy Office of the Climate Bureau.\n\n\n\n8.1.6 Practical on GEE\nHere I chose to use two geographic datasets, Landsat and Modis, to calculate the temperature of Qinhuangdao. landsat has a higher resolution than Modis, but requires a series of computational processes to express the temperature in degrees Celsius. In addition, Landsat data is collected at a slower rate, with remote sensing images taken twice a month. Modis, on the other hand, collects data every two days, so the time series analysis using it is a good option, but it cannot be used for spatial analysis.\n\n\n\n\n\nthe Temperature with Landsat\n\n\n\n\n\n\n\n\n\nthe Temperature with MODIS\n\n\n\n\n\n\n\n\n\nthe time series of temperature with MODIS\n\n\n\n\n\n\n8.1.7 Application\nI learned that the US Environmental Protection Agenda provides an idea for us to learn from on how to measure heat islands.\n\nClarifying Objectives\nIn most cases, there are two main reasons for measuring heat island intensity:\n\n\n1.energy\n\nHigher urban temperatures drive demand for air conditioning, leading to higher energy bills during the warmer months of the year. Analyzing how temperatures in an urban area differ from those in the surrounding region will help you quantify the energy impacts.\n\n2.public risk\n\nHeat islands can contribute to poor air quality, magnify the impacts of extreme heat events, and put people’s health at higher risk. Identifying hot spots within a city can help focus interventions where they are most needed during heat waves.\n\nIdentifying Data Needs\n\n1.research area\nAssessments focused primarily on energy-related impacts of heat islands typically compare the temperature in the overall urban area with the temperature in the surrounding rural area to determine how much additional energy demand is caused by the urban heat island.\nAssessments focused on health-related impacts of heat islands typically focus on assessing the differences in air temperatures among different locations within the city (i.e., identifying hot spots).\n\n2.data type\n\nAir temperatures\n\nBetween 2012 and 2013, researchers at the University of Wisconsin installed 150 temperature and relative humidity sensors at a height of 3.5 meters on streetlight and utility poles in and around Madison, Wisconsin. The sensors automatically recorded instantaneous temperature and relative humidity every 15 minutes.\n\nSurface temperatures\n\nResearchers at Arizona State University used MODIS and Landsat satellite data to examine changes in the City of Phoenix’s surface urban heat island over space and time, in relation to changes in land use cover, from 2000–2014.\n3.how to analysis\nAnalysis with the Surface temperatures\nThe main objective of this study is to examine which regions within the Phoenix metropolitan area have experienced statistically significant LST increases and decreases compared to surrounding non-urbanized areas for both daytime and nighttime.\nStudy area:The Phoenix metropolitan area is located in central Arizona, USA, and is the sixth largest U.S. city。The daily high temperature exceeds 37.8 °C for an average of 110 days every year, which normally occurs from late May until early September. The highest temperature can reach more than 43.3 °C for an annual average of 18 days. The study area has diverse LULC types, including commercial, industrial, residential areas, undisturbed desert, agriculture, grassland, and water bodies.\n\n\n\n\n\n\nstudy area\n\n\n\n\nMethodology:This study used MODIS LST 8-day composite images of daytime and nighttime from 2000 to 2014.Metropolitan and rural buffer pixels were extracted from the MODIS LST images and the pixel values of the daytime and nighttime images were converted to LST in degrees Celsius (°C). The average metropolitan and buffer surface temperature images were then calculated by averaging four June surface temperature images per year (two images in 2001) to obtain 15 daytime and 15 nighttime average surface temperature images. Finally, the average annual surface temperature for the entire buffer zone was calculated and subtracted from each Phoenix pixel to produce a surface temperature difference map.\nOutput：These results indicate that most significant changes of SUHI intensity have taken place on the outskirts of the city with no significant changes observed in existing, developed, urban areas. The areas being continuously cooled during the daytime are all located on the city outskirts.\n\nThe red pixels have positive slope coefficients representing the areas with increasingly higher LST than the surrounding non-urbanized areas, while the areas that have negative slope coefficients (blue pixels) represent an increasingly lower LST than the non-urbanized areas during the study period (Figure 4). The greater the absolute value of the slope coefficient is, the higher the ΔTu-r change will be.\n\n\n\n\n\n\nlope coefficient maps for daytime LST trend analysis\n\n\n\n\n\n\n\n\n\nlope coefficient maps for nighttime LST trend analysis\n\n\n\n\nBased on the results and findings from this research, we would recommend that increase in vegetation cover, with the trade-off between water and energy carefully studied, can be a potentially effective means to mitigate the UHI effect in those high SUHI intensity areas. It is an easy, low-cost, and feasible way to lower the UHI effect and conserve energy.\nComment\nAlthough the spatial resolution of the MODIS LST images (1000 m) is slightly coarse, a total of 2766 pixels were assessed for the entire Phoenix metropolitan area, a relatively large sample size. Therefore, the problem of the resolution is not considered. For this study, we restricted our analysis to the month of June, as Phoenix experiences relatively hot, dry, sunny and calm weather conditions for much of the month. As such, it is considered an ideal time period for urban LST. I learn that when I research the UHI, I need to consider the aspect of climate to choose the data in the study.\n\n\n8.1.8 Reflection\nAs the goal of sustainable urban development continues to be emphasized, how to measure urban heat island intensity and how to address it is a key concern for governments. It is important to note that governments should not limit their knowledge of urban mitigation to planning strategies. It is also important to visualise urban heat island areas through remote sensing data analysis and to target specific strategies. We need to learn from other good examples of implementation measures, such as forming urban green belts, increasing urban wetlands, increasing vertical greening of buildings, etc., as mentioned in the study notes. Through studying the literature during the week, I found that there are very different ways to study urban heat islands, and so far I have only studied urban heat island intensity measured by urban surface temperature. There is a lack of consideration of the effects of urban building density, air pollution and other factors. This will be a direction of study for me after this."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Classificaiton 2",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Landcover classification\n\n7.1.1.1 Object based image analysis and sub pixel analysis(OBIA)\nTraditional pixel-based image classification assigns a land cover class per pixel. All pixels are the same size, same shape, and don’t have any concept of their neighbors.\nHowever, OBIA segments an image grouping small pixels together into vector objects. Instead of a per-pixel basis, segmentation automatically digitizes the image for you.\n\n\n\n\n\n\nUse Euclidean distance in SLIC. Source: [Nowosad 2021](https://jakubnowosad.com/ogh2021/#10\n\n\n\n\ntwo basic principles of OBIA are:\n\n\nSEGMENTATION: Break the image up into objects representing land-based features.\n\nCLASSIFICATION: Classify those objects using their shape, size, spatial and spectral There are many methods in object-based image analysis. Superpixels consider the similarity of pixels and homogeneity of the pixels, and Simple Linear Iterative Clustering (SLIC) is one of most common method to generate superpixels.\n\n\nApplication\n\n1.Medical Imaging\n\n2.Object detection (Face, pedestrian detection)\n\n3.Recognition Tasks (Face, Fingerprint recognition)\n\n4.Video Surveillance]\n\n\n\n7.1.1.2 Sub-pixel analysis\nThe sub-pixel analysis is a digital image processing technique that achieves subpixel resolution in images. This means that subpixel resolution can be obtained when the information of a picture exceeds its nominal pixel resolution. For example, in an idea, a position is represented as an integer value (x,y) coordinates and a place where a fractional pixel location might be given.\n\n\n\n\n\nComparison of true colour high spatial resolution data (a) and Landsat surface reflectance (b) highlighting the spatial detail captured by high-resolution imagery (c) and the same areas as observed by Landsat (d) for the subset East Beechboro used within this study. Source: Tandfonline\n\n\n\n\n\n\n7.1.1.3 Accuracy assessment\nIn remote sensing we focus on:\n\nPA Producer accuracy (recall or true positive rate or sensitivity)\n\nUA User’s accuracy (consumer’s accuracy or precision or positive predictive value\n\nOA the (overall) accuracy\n\n\n\n\n\n\nBinary confusion matrix . Source: TBarsi et al. 2018\n\n\n\n\n\n\n7.1.1.4 Test and training data\nWhen we fit the model, there are some approach to fit the model better.\n\ntrain and test split The dataset is divided into training and testing sets. The training set is used to train the model, while the test set is used to evaluate the model’s performance. This aims to prevent overfitting, where the model performs well on the training data but not on the new data.\ncross validation\n\nIt tests the model’s performance on the other subsets by dividing the dataset into subsets and then training the model on one of the subsets. This process is repeated multiple times, training and testing with a different subgroup each time. Finally, the average of all test results is used to evaluate the model’s performance.\n\n\n\n\n\ncross validation. Source: scikit-learn\n\n\n\n\nSpatial cross validation\n\nIf there is the patial autocorrelation between training and test sets,we should consider the spatial cross validation.Spatial cross-validation is a method for assessing the performance of spatial prediction models. It is similar to normal cross-validation but takes into account spatial relationships when dividing the dataset. The dataset is divided into subsets in spatial cross-validation, with each subset containing neighbouring observations. The model is then trained on one subset and tested on the performance of the model on the other subsets. This process is repeated several times, each time using a different subset for training and testing.\n\n\n\n\n\nIllustration of default cross-validation vs. spatial cross-validation. Source: Lovelace, et al\n\n\n\n\n\n\n7.1.1.5 GEE on practical\nFor this practice I positioned myself in Beijing and classified the polygon into high density urban go, low density urban areas, water bodies and agricultural land for land cover.\n\n\n\n\n\n\nNDVI\n\n\n\n\n\n\n\n\n\nSUBPIXEL\n\n\n\n\n\n\n\n\n\nObject"
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Classificaiton 2",
    "section": "7.2 Application",
    "text": "7.2 Application\nMapping land cover and land use from object-based classification: an example from a complex agricultural landscape\nThe author quantitatively compared the results of OBIA-based versus per-pixel classifications for both land cover and land use, respectively. Our results show that land-cover classification was not significantly improved when OBIA-based methods were used. Although overall classification accuracy was modest, land-use classification was significantly improved when OBIA-based methods were applied using both spectral and spatial/geometric features of image objects, but not when spectral or spatial/geometric features were used independently.\nstudy area The study area for this analysis was an area along the Ukraine–Poland border, encompassing parts of Volyn oblast (on the Ukrainian side) and Lubelski volveldeship on the Polish side.\n\nthe reason :\nIt is heavily agricultural, and because it encompasses a variety of agricultural practices that result in fields with contrasting sizes and shapes. It therefore provides a challenging landscape on which to test whether object-based methods can improve land-cover or land-use classification.\n\n\n\n\n\n\nMap of the study area. Latitude and longitude coordinates for the lower left and upper right are in degrees. Source: Goodin, et al\n\n\n\n\nMethodology\n\n\nusing both spectral and spatial/geometric object features (henceforth referred to as OBIA-combined)\n\nusing only object spectral features (OBIA-spectral)\n\nusing only spatial and geometric object properties (OBIA-spatial)\n\n\nOutput\n\n\n\n\n\nResults from the per-pixel (a) and OBIA-combined (b) classifications\n\n\n\n\ncomment:The reading shows that object-based methods can improve the accuracy of land-use classifications, and a visual comparison of OBIA combined and pixel-by-pixel classification results shows that pixel-by-pixel classification has more fine-scale variability or heterogeneity than object-based classification. It is worth noting that, the results presented here were obtained with moderate spatial resolution data. The results may or may not be generalizable to classification performed with finer or coarser resolution data."
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Classificaiton 2",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThrough this week’s study of obia, I have learnt that it is a powerful tool in image analysis and remote sensing applications. These techniques have revolutionised the way we analyse and interpret satellite and aerial imagery, allowing us to extract meaningful information from complex images that would be difficult to obtain using traditional pixel-based methods. These analytical methods have revolutionised the way we analyse and interpret remote sensing data, allowing us to extract more accurate and meaningful information from complex imagery. Through my literature reading, I understand that these techniques are equally important for disaster response, and will study other literature carefully when I have time afterwards."
  }
]